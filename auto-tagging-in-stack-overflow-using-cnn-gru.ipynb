{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8976596,"sourceType":"datasetVersion","datasetId":5404970},{"sourceId":8977004,"sourceType":"datasetVersion","datasetId":5405251}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd #here just used to read csv file\nfrom sklearn.preprocessing import MultiLabelBinarizer#basically transforms lists to binary indicator matrices ,presecnce or absence marked by 1 or 0 ((Try print(mlb.classes)))\nfrom collections import Counter#counts for the frequency of all the tags and thus gives us top 10 tags\nimport ast#abstract syntax tree\nfrom tensorflow.keras.preprocessing.text import Tokenizer#for text processing\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences #pads sequences to same length\nimport tensorflow as tf#just importing tensorflow\nfrom tensorflow.keras.models import Model #used to create a model in Keras. It is the central component for defining and training neural networks.\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, Conv1D, GlobalMaxPooling1D, Dense, Concatenate, Dropout, BatchNormalization, Attention\nfrom tensorflow.keras.optimizers import RMSprop# uses an adaptive learning rate and root mean square propagation to improve training.\nfrom tensorflow.keras.callbacks import EarlyStopping# callback that stops training when a monitored metric has stopped improving.\nimport time #Time info\nimport psutil #CPU info\nimport subprocess #GPU info\nimport warnings #handling\nimport ipywidgets as widgets #for UI componentsa\nfrom IPython.display import display, HTML #for html and UI display\nfrom sklearn.metrics import precision_score #For Precision\n\n\n# Ignore warnings\nwarnings.filterwarnings('ignore')\n\n# Function to get GPU memory usage\ndef get_gpu_memory():\n    try:\n        result = subprocess.check_output(\n            ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'], encoding='utf-8'\n        )\n        gpu_memory = int(result.strip().split('\\n')[0])\n    except Exception as e:\n        gpu_memory = 0\n    return gpu_memory\n\n# Function to get CPU memory usage\ndef get_cpu_memory():\n    return psutil.virtual_memory().used / (1024 ** 3)  # Convert bytes to GB\n\n# Start session\ndef start_session():\n    # Record the start time and initial memory usage\n    start_time = time.time()\n    initial_cpu_memory = get_cpu_memory()\n    initial_gpu_memory = get_gpu_memory()\n\n    # Load the dataset with a specified encoding\n    file_path = '/kaggle/input/150k-rows/150k.csv'  # Update this path as per your dataset location on Kaggle\n    data = pd.read_csv(file_path, encoding='latin1')\n\n    # Display the first few rows of the dataset\n    display(data.iloc[:10, [0, -1]])\n\n    # Calculate and display the number of rows and dataset size\n    num_rows = len(data)\n    dataset_size = data.memory_usage(index=True).sum() / (1024 ** 2)  # Convert bytes to MB\n    print(\"\\nBefore filtering:\")\n    print(f\"Number of rows: {num_rows}\")\n    print(f\"Dataset size: {dataset_size:.2f} MB\")\n\n    # Function to convert tag strings to lists\n    def convert_tags(tag_string):\n        try:\n            return ast.literal_eval(tag_string)\n        except (ValueError, SyntaxError):\n            return []\n\n    # Convert tag strings to lists, handling NaN values\n    data['Tags'] = data['Tags'].fillna('[]').apply(convert_tags)\n\n    # Extract the top 10 most frequent tags\n    all_tags = [tag for tags in data['Tags'] for tag in tags]\n    top_10_tags = [tag for tag, count in Counter(all_tags).most_common(10)]\n\n    # Filter the dataset to include only questions with these top 10 tags\n    data['Top_Tags'] = data['Tags'].apply(lambda tags: [tag for tag in tags if tag in top_10_tags])\n    data = data[data['Top_Tags'].map(len) > 0]\n\n    # Tokenize the questions\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(data['Questions'])\n    sequences = tokenizer.texts_to_sequences(data['Questions'])\n\n    # Pad the sequences\n    max_sequence_length = 150  # Increased sequence length\n    X = pad_sequences(sequences, maxlen=max_sequence_length)\n\n    # Convert tags to a binary format\n    mlb = MultiLabelBinarizer(classes=top_10_tags)\n    y = mlb.fit_transform(data['Top_Tags'])\n\n    # Manually split the data into training (first 80%) and validation (next 20%) sets\n    split_index = int(0.8 * len(X))\n    X_train, X_val = X[:split_index], X[split_index:]\n    y_train, y_val = y[:split_index], y[split_index:]\n\n    # Define model parameters\n    embedding_dim = 128\n    gru_units = 64\n    num_filters = 256\n    kernel_size = 5\n    dense_units = 64\n    dropout_rate = 0.5061\n    num_classes = len(top_10_tags)\n    vocab_size = len(tokenizer.word_index) + 1\n\n    # Define the input layer\n    input_layer = Input(shape=(max_sequence_length,))\n\n    # Embedding layer\n    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)(input_layer)\n\n    # Bidirectional GRU layer\n    gru_layer = Bidirectional(GRU(units=gru_units, return_sequences=True))(embedding_layer)\n    gru_layer = Dropout(dropout_rate)(gru_layer)\n    gru_layer = BatchNormalization()(gru_layer)\n\n    # Attention layer\n    attention_layer = Attention()([gru_layer, gru_layer])\n\n    # CNN layer\n    cnn_layer = Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu')(embedding_layer)\n    cnn_layer = GlobalMaxPooling1D()(cnn_layer)\n    cnn_layer = Dropout(dropout_rate)(cnn_layer)\n    cnn_layer = BatchNormalization()(cnn_layer)\n\n    # Concatenate GRU and CNN layers\n    concatenated_layer = Concatenate()([attention_layer[:, -1, :], cnn_layer])\n\n    # Dense layer\n    dense_layer = Dense(units=dense_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(concatenated_layer)\n    dense_layer = Dropout(dropout_rate)(dense_layer)\n    dense_layer = BatchNormalization()(dense_layer)\n\n    # Output layer\n    output_layer = Dense(units=num_classes, activation='sigmoid')(dense_layer)\n\n    # Define the model\n    model = Model(inputs=input_layer, outputs=output_layer)\n\n    # Compile the model with RMSprop optimizer\n    optimizer = RMSprop(learning_rate=0.001)  # Adjust learning rate if needed\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Print the model summary\n    print()\n    model.summary()\n    print()\n\n    # Train the model with Early Stopping\n    batch_size = 32\n    epochs = 10\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[early_stopping])\n\n    # Evaluate the model\n    loss, accuracy = model.evaluate(X_val, y_val)\n\n    # Calculate precision\n    y_pred = model.predict(X_val)\n    y_pred_binary = (y_pred > 0.5).astype(int)\n    precision = precision_score(y_val, y_pred_binary, average='micro')\n\n    # Display accuracy and precision in percentage\n    print(f\"\\nValidation Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"Precision: {precision * 100:.2f}%\")\n\n\n    # Record the end time and final memory usage\n    end_time = time.time()\n    final_cpu_memory = get_cpu_memory()\n    final_gpu_memory = get_gpu_memory()\n\n    # Calculate the execution time and memory usage\n    execution_time = end_time - start_time\n    cpu_memory_used = final_cpu_memory - initial_cpu_memory\n    gpu_memory_used = final_gpu_memory - initial_gpu_memory\n    \n    # Calculate and display the number of rows and dataset size\n    num_rows = len(data)\n    dataset_size = data.memory_usage(index=True).sum() / (1024 ** 2)  # Convert bytes to MB\n    print(\"\\nAfter filtering:\")\n    print(f\"Number of rows: {num_rows}\")\n    print(f\"Dataset size: {dataset_size:.2f} MB\")\n\n    # Print the results\n    print(f\"\\nExecution Time: {execution_time:.2f} seconds\")\n    print(f\"CPU Memory Used: {cpu_memory_used:.2f} GB\")\n    print(f\"GPU Memory Used: {gpu_memory_used} MB\")\n\n    # Display \"TOP 10 PREDICTED TAGS\" in bold\n    print(\" \")\n    display(HTML(\"<b>TOP 10 PREDICTED TAGS</b>\"))\n\n    # Display top 10 tags in table format\n    top_10_tags_html = \"<table><tr><th>Rank</th><th>Tag</th></tr>\"\n    for i, tag in enumerate(top_10_tags, start=1):\n        top_10_tags_html += f\"<tr><td>{i}</td><td>{tag}</td></tr>\"\n    top_10_tags_html += \"</table>\"\n    display(HTML(top_10_tags_html))\n    \n    import pickle\n\n    # Save the model\n    model.save(\"tag_predictor_model.h5\")\n    # Save tokenizer\n    with open(\"tokenizer.pkl\", \"wb\") as f:\n        pickle.dump(tokenizer, f)\n    # Save MultiLabelBinarizer\n    with open(\"mlb.pkl\", \"wb\") as f:\n        pickle.dump(mlb, f)\n    print(\"Model, tokenizer, and label binarizer saved successfully.\")\n\n# Start the session and get the prediction function\npredict_tags_fn, top_10_tags, tokenizer, model = start_session()\n\n    \n","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-06-29T06:11:02.782820Z","iopub.execute_input":"2025-06-29T06:11:02.783150Z","iopub.status.idle":"2025-06-29T06:24:26.411808Z","shell.execute_reply.started":"2025-06-29T06:11:02.783108Z","shell.execute_reply":"2025-06-29T06:24:26.410608Z"}},"outputs":[{"name":"stderr","text":"2025-06-29 06:11:05.731922: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-06-29 06:11:05.732054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-06-29 06:11:05.889230: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                           Questions  \\\n0  I am very new to C# and I have a question. I d...   \n1  The code runs fine on React 16.8, yet freezes ...   \n2  I have a python script with:\\n\\n```\\nos.enviro...   \n3  I have been trying to fetch the data from my F...   \n4  I have a migration like this:   \\n\\n```\\nSchem...   \n5  I need to SELECT the 5 most recent notificatio...   \n6  I have a vector\\n\\n```\\nmyVec <- c('1.2','asd'...   \n7  I stumbled upon the Solver function in my sear...   \n8  I am facing a weird bug.\\n\\nHere is the code f...   \n9  I have some on-premise based frontend java ser...   \n\n                                                Tags  \n0                [\"c#\",\"asp.net-mvc\",\"if-statement\"]  \n1  [\"reactjs\",\"react-hooks\",\"use-effect\",\"js-cook...  \n2        [\"python\",\"docker\",\"environment-variables\"]  \n3  [\"android\",\"firebase\",\"listview\",\"firebase-rea...  \n4                                [\"mysql\",\"laravel\"]  \n5                                 [\"abap\",\"opensql\"]  \n6                              [\"r\",\"regex\",\"grepl\"]  \n7                  [\"excel\",\"vba\",\"random\",\"solver\"]  \n8              [\"python\",\"matplotlib\",\"jupyter-lab\"]  \n9  [\"database\",\"oracle\",\"amazon-web-services\",\"cl...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am very new to C# and I have a question. I d...</td>\n      <td>[\"c#\",\"asp.net-mvc\",\"if-statement\"]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The code runs fine on React 16.8, yet freezes ...</td>\n      <td>[\"reactjs\",\"react-hooks\",\"use-effect\",\"js-cook...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have a python script with:\\n\\n```\\nos.enviro...</td>\n      <td>[\"python\",\"docker\",\"environment-variables\"]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I have been trying to fetch the data from my F...</td>\n      <td>[\"android\",\"firebase\",\"listview\",\"firebase-rea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I have a migration like this:   \\n\\n```\\nSchem...</td>\n      <td>[\"mysql\",\"laravel\"]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I need to SELECT the 5 most recent notificatio...</td>\n      <td>[\"abap\",\"opensql\"]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I have a vector\\n\\n```\\nmyVec &lt;- c('1.2','asd'...</td>\n      <td>[\"r\",\"regex\",\"grepl\"]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>I stumbled upon the Solver function in my sear...</td>\n      <td>[\"excel\",\"vba\",\"random\",\"solver\"]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>I am facing a weird bug.\\n\\nHere is the code f...</td>\n      <td>[\"python\",\"matplotlib\",\"jupyter-lab\"]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>I have some on-premise based frontend java ser...</td>\n      <td>[\"database\",\"oracle\",\"amazon-web-services\",\"cl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nBefore filtering:\nNumber of rows: 150013\nDataset size: 3.43 MB\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │ \u001b[38;5;34m62,617,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m74,496\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m146\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m164,096\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,640\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ batch_normalizat… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">62,617,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">146</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ batch_normalizat… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,883,274\u001b[0m (239.88 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,883,274</span> (239.88 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,882,378\u001b[0m (239.88 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,882,378</span> (239.88 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.4965 - loss: 0.5458 - val_accuracy: 0.7909 - val_loss: 0.1429\nEpoch 2/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.7689 - loss: 0.1667 - val_accuracy: 0.8005 - val_loss: 0.1355\nEpoch 3/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.7851 - loss: 0.1547 - val_accuracy: 0.8029 - val_loss: 0.1292\nEpoch 4/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.7976 - loss: 0.1477 - val_accuracy: 0.8072 - val_loss: 0.1281\nEpoch 5/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.8039 - loss: 0.1430 - val_accuracy: 0.8113 - val_loss: 0.1274\nEpoch 6/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 36ms/step - accuracy: 0.8106 - loss: 0.1385 - val_accuracy: 0.8099 - val_loss: 0.1280\nEpoch 7/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.8144 - loss: 0.1350 - val_accuracy: 0.8065 - val_loss: 0.1272\nEpoch 8/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.8234 - loss: 0.1318 - val_accuracy: 0.8107 - val_loss: 0.1261\nEpoch 9/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.8251 - loss: 0.1293 - val_accuracy: 0.8136 - val_loss: 0.1266\nEpoch 10/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 36ms/step - accuracy: 0.8346 - loss: 0.1251 - val_accuracy: 0.8085 - val_loss: 0.1299\n\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.1266\n\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n\nValidation Accuracy: 81.07%\nPrecision: 88.43%\n\nAfter filtering:\nNumber of rows: 81261\nDataset size: 3.10 MB\n\nExecution Time: 787.61 seconds\nCPU Memory Used: 2.01 GB\nGPU Memory Used: 14078 MB\n \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<b>TOP 10 PREDICTED TAGS</b>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table><tr><th>Rank</th><th>Tag</th></tr><tr><td>1</td><td>python</td></tr><tr><td>2</td><td>javascript</td></tr><tr><td>3</td><td>java</td></tr><tr><td>4</td><td>c#</td></tr><tr><td>5</td><td>android</td></tr><tr><td>6</td><td>html</td></tr><tr><td>7</td><td>php</td></tr><tr><td>8</td><td>reactjs</td></tr><tr><td>9</td><td>python-3.x</td></tr><tr><td>10</td><td>sql</td></tr></table>"},"metadata":{}},{"name":"stdout","text":"Model, tokenizer, and label binarizer saved successfully.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 216\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel, tokenizer, and label binarizer saved successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Start the session and get the prediction function\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m predict_tags_fn, top_10_tags, tokenizer, model \u001b[38;5;241m=\u001b[39m start_session()\n","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"],"ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"import pickle\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Load model and objects\nmodel = load_model(\"tag_predictor_model.h5\")\n\nwith open(\"tokenizer.pkl\", \"rb\") as f:\n    tokenizer = pickle.load(f)\n\nwith open(\"mlb.pkl\", \"rb\") as f:\n    mlb = pickle.load(f)\n\n# Redefine max length and tag list\nmax_sequence_length = 150\ntop_10_tags = mlb.classes_\n\n# Function to predict tags for a given question\ndef predict_tags(question, threshold=0.5):\n    if question:\n        sequence = tokenizer.texts_to_sequences([question])\n        padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n        prediction = model.predict(padded_sequence)\n        \n        # Adjust threshold dynamically based on the distribution of probabilities\n        adjusted_threshold = np.percentile(prediction, 70)  # Example: using 70th percentile\n        \n        predicted_tags = mlb.inverse_transform(prediction > adjusted_threshold)\n        return predicted_tags[0]\n    return []\nreturn predict_tags, top_10_tags, tokenizer, model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:09:26.662989Z","iopub.execute_input":"2025-06-29T06:09:26.663437Z","iopub.status.idle":"2025-06-29T06:09:27.284156Z","shell.execute_reply.started":"2025-06-29T06:09:26.663411Z","shell.execute_reply":"2025-06-29T06:09:27.282854Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load model and objects\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtag_predictor_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    177\u001b[0m         filepath,\n\u001b[1;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/legacy/saving/legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[0;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n","File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'tag_predictor_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"],"ename":"FileNotFoundError","evalue":"[Errno 2] Unable to synchronously open file (unable to open file: name = 'tag_predictor_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\ndef predict_with_confidence(question):\n    sequence = tokenizer.texts_to_sequences([question])\n    padded_sequence = pad_sequences(sequence, maxlen=150)\n    prediction = model.predict(padded_sequence)[0]  # Get first sample's prediction\n    tag_scores = {tag: score for tag, score in zip(top_10_tags, prediction)}\n    \n    # Sort by confidence\n    sorted_tags = sorted(tag_scores.items(), key=lambda x: x[1], reverse=True)\n    \n    # Get top tag and confidence\n    best_tag, best_score = sorted_tags[0]\n    \n    # Also get all tags above threshold (0.5 or dynamic)\n    predicted_tags = [tag for tag, score in tag_scores.items() if score > 0.35]\n\n    return best_tag, best_score, predicted_tags, tag_scores\n\n# Loop\nwhile True:\n    question = input(\"\\nEnter your question (or type 'exit' to quit): \").strip()\n    if question.lower() == 'exit':\n        print(\"Exiting prediction loop.\")\n        break\n\n    best_tag, best_score, predicted_tags, tag_scores = predict_with_confidence(question)\n\n    print(f\"\\nPredicted Top Tag: {best_tag} (Confidence: {best_score:.2f})\")\n    print(f\"Other Relevant Tags: {', '.join(predicted_tags) if predicted_tags else 'None above threshold'}\")\n    print(\"All Tag Scores:\")\n    for tag, score in tag_scores.items():\n        print(f\"  {tag}: {score:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:09:27.284810Z","iopub.status.idle":"2025-06-29T06:09:27.285136Z","shell.execute_reply.started":"2025-06-29T06:09:27.284993Z","shell.execute_reply":"2025-06-29T06:09:27.285006Z"}},"outputs":[],"execution_count":null}]}