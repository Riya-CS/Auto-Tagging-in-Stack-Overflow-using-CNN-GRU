{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8976596,"sourceType":"datasetVersion","datasetId":5404970},{"sourceId":8977004,"sourceType":"datasetVersion","datasetId":5405251}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd #here just used to read csv file\nfrom sklearn.preprocessing import MultiLabelBinarizer#basically transforms lists to binary indicator matrices ,presecnce or absence marked by 1 or 0 ((Try print(mlb.classes)))\nfrom collections import Counter#counts for the frequency of all the tags and thus gives us top 10 tags\nimport ast#abstract syntax tree\nfrom tensorflow.keras.preprocessing.text import Tokenizer#for text processing\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences #pads sequences to same length\nimport tensorflow as tf#just importing tensorflow\nfrom tensorflow.keras.models import Model #used to create a model in Keras. It is the central component for defining and training neural networks.\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, Conv1D, GlobalMaxPooling1D, Dense, Concatenate, Dropout, BatchNormalization, Attention\nfrom tensorflow.keras.optimizers import RMSprop# uses an adaptive learning rate and root mean square propagation to improve training.\nfrom tensorflow.keras.callbacks import EarlyStopping# callback that stops training when a monitored metric has stopped improving.\nimport time #Time info\nimport psutil #CPU info\nimport subprocess #GPU info\nimport warnings #handling\nimport ipywidgets as widgets #for UI componentsa\nfrom IPython.display import display, HTML #for html and UI display\nfrom sklearn.metrics import precision_score #For Precision\n\n\n# Ignore warnings\nwarnings.filterwarnings('ignore')\n\n# Function to get GPU memory usage\ndef get_gpu_memory():\n    try:\n        result = subprocess.check_output(\n            ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'], encoding='utf-8'\n        )\n        gpu_memory = int(result.strip().split('\\n')[0])\n    except Exception as e:\n        gpu_memory = 0\n    return gpu_memory\n\n# Function to get CPU memory usage\ndef get_cpu_memory():\n    return psutil.virtual_memory().used / (1024 ** 3)  # Convert bytes to GB\n\n# Start session\ndef start_session():\n    # Record the start time and initial memory usage\n    start_time = time.time()\n    initial_cpu_memory = get_cpu_memory()\n    initial_gpu_memory = get_gpu_memory()\n\n    # Load the dataset with a specified encoding\n    file_path = '/kaggle/input/150k-rows/150k.csv'  # Update this path as per your dataset location on Kaggle\n    data = pd.read_csv(file_path, encoding='latin1')\n\n    # Display the first few rows of the dataset\n    display(data.iloc[:10, [0, -1]])\n\n    # Calculate and display the number of rows and dataset size\n    num_rows = len(data)\n    dataset_size = data.memory_usage(index=True).sum() / (1024 ** 2)  # Convert bytes to MB\n    print(\"\\nBefore filtering:\")\n    print(f\"Number of rows: {num_rows}\")\n    print(f\"Dataset size: {dataset_size:.2f} MB\")\n\n    # Function to convert tag strings to lists\n    def convert_tags(tag_string):\n        try:\n            return ast.literal_eval(tag_string)\n        except (ValueError, SyntaxError):\n            return []\n\n    # Convert tag strings to lists, handling NaN values\n    data['Tags'] = data['Tags'].fillna('[]').apply(convert_tags)\n\n    # Extract the top 10 most frequent tags\n    all_tags = [tag for tags in data['Tags'] for tag in tags]\n    top_10_tags = [tag for tag, count in Counter(all_tags).most_common(10)]\n\n    # Filter the dataset to include only questions with these top 10 tags\n    data['Top_Tags'] = data['Tags'].apply(lambda tags: [tag for tag in tags if tag in top_10_tags])\n    data = data[data['Top_Tags'].map(len) > 0]\n\n    # Tokenize the questions\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(data['Questions'])\n    sequences = tokenizer.texts_to_sequences(data['Questions'])\n\n    # Pad the sequences\n    max_sequence_length = 150  # Increased sequence length\n    X = pad_sequences(sequences, maxlen=max_sequence_length)\n\n    # Convert tags to a binary format\n    mlb = MultiLabelBinarizer(classes=top_10_tags)\n    y = mlb.fit_transform(data['Top_Tags'])\n\n    # Manually split the data into training (first 80%) and validation (next 20%) sets\n    split_index = int(0.8 * len(X))\n    X_train, X_val = X[:split_index], X[split_index:]\n    y_train, y_val = y[:split_index], y[split_index:]\n\n    # Define model parameters\n    embedding_dim = 128\n    gru_units = 64\n    num_filters = 256\n    kernel_size = 5\n    dense_units = 64\n    dropout_rate = 0.5061\n    num_classes = len(top_10_tags)\n    vocab_size = len(tokenizer.word_index) + 1\n\n    # Define the input layer\n    input_layer = Input(shape=(max_sequence_length,))\n\n    # Embedding layer\n    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)(input_layer)\n\n    # Bidirectional GRU layer\n    gru_layer = Bidirectional(GRU(units=gru_units, return_sequences=True))(embedding_layer)\n    gru_layer = Dropout(dropout_rate)(gru_layer)\n    gru_layer = BatchNormalization()(gru_layer)\n\n    # Attention layer\n    attention_layer = Attention()([gru_layer, gru_layer])\n\n    # CNN layer\n    cnn_layer = Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu')(embedding_layer)\n    cnn_layer = GlobalMaxPooling1D()(cnn_layer)\n    cnn_layer = Dropout(dropout_rate)(cnn_layer)\n    cnn_layer = BatchNormalization()(cnn_layer)\n\n    # Concatenate GRU and CNN layers\n    concatenated_layer = Concatenate()([attention_layer[:, -1, :], cnn_layer])\n\n    # Dense layer\n    dense_layer = Dense(units=dense_units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(concatenated_layer)\n    dense_layer = Dropout(dropout_rate)(dense_layer)\n    dense_layer = BatchNormalization()(dense_layer)\n\n    # Output layer\n    output_layer = Dense(units=num_classes, activation='sigmoid')(dense_layer)\n\n    # Define the model\n    model = Model(inputs=input_layer, outputs=output_layer)\n\n    # Compile the model with RMSprop optimizer\n    optimizer = RMSprop(learning_rate=0.001)  # Adjust learning rate if needed\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Print the model summary\n    print()\n    model.summary()\n    print()\n\n    # Train the model with Early Stopping\n    batch_size = 32\n    epochs = 10\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[early_stopping])\n\n    # Evaluate the model\n    loss, accuracy = model.evaluate(X_val, y_val)\n\n    # Calculate precision\n    y_pred = model.predict(X_val)\n    y_pred_binary = (y_pred > 0.5).astype(int)\n    precision = precision_score(y_val, y_pred_binary, average='micro')\n\n    # Display accuracy and precision in percentage\n    print(f\"\\nValidation Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"Precision: {precision * 100:.2f}%\")\n\n\n    # Record the end time and final memory usage\n    end_time = time.time()\n    final_cpu_memory = get_cpu_memory()\n    final_gpu_memory = get_gpu_memory()\n\n    # Calculate the execution time and memory usage\n    execution_time = end_time - start_time\n    cpu_memory_used = final_cpu_memory - initial_cpu_memory\n    gpu_memory_used = final_gpu_memory - initial_gpu_memory\n    \n    # Calculate and display the number of rows and dataset size\n    num_rows = len(data)\n    dataset_size = data.memory_usage(index=True).sum() / (1024 ** 2)  # Convert bytes to MB\n    print(\"\\nAfter filtering:\")\n    print(f\"Number of rows: {num_rows}\")\n    print(f\"Dataset size: {dataset_size:.2f} MB\")\n\n    # Print the results\n    print(f\"\\nExecution Time: {execution_time:.2f} seconds\")\n    print(f\"CPU Memory Used: {cpu_memory_used:.2f} GB\")\n    print(f\"GPU Memory Used: {gpu_memory_used} MB\")\n\n    # Display \"TOP 10 PREDICTED TAGS\" in bold\n    print(\" \")\n    display(HTML(\"<b>TOP 10 PREDICTED TAGS</b>\"))\n\n    # Display top 10 tags in table format\n    top_10_tags_html = \"<table><tr><th>Rank</th><th>Tag</th></tr>\"\n    for i, tag in enumerate(top_10_tags, start=1):\n        top_10_tags_html += f\"<tr><td>{i}</td><td>{tag}</td></tr>\"\n    top_10_tags_html += \"</table>\"\n    display(HTML(top_10_tags_html))\n    \n    import pickle\n\n    # Save the model\n    model.save(\"tag_predictor_model.h5\")\n    # Save tokenizer\n    with open(\"tokenizer.pkl\", \"wb\") as f:\n        pickle.dump(tokenizer, f)\n    # Save MultiLabelBinarizer\n    with open(\"mlb.pkl\", \"wb\") as f:\n        pickle.dump(mlb, f)\n    print(\"Model, tokenizer, and label binarizer saved successfully.\")\n\n    def predict_tags_fn(question, threshold=0.5):\n        if question:\n            sequence = tokenizer.texts_to_sequences([question])\n            padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n            prediction = model.predict(padded_sequence)\n            adjusted_threshold = np.percentile(prediction, 70)\n            predicted_tags = mlb.inverse_transform(prediction > adjusted_threshold)\n            return predicted_tags[0]\n        return []\n\n\n    return predict_tags_fn, top_10_tags, tokenizer, model\n\npredict_tags_fn, top_10_tags, tokenizer, model = start_session()\n","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-07-18T07:55:11.865949Z","iopub.execute_input":"2025-07-18T07:55:11.866275Z"}},"outputs":[{"name":"stderr","text":"2025-07-18 07:55:15.764447: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-07-18 07:55:15.764613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-07-18 07:55:15.909244: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                           Questions  \\\n0  I am very new to C# and I have a question. I d...   \n1  The code runs fine on React 16.8, yet freezes ...   \n2  I have a python script with:\\n\\n```\\nos.enviro...   \n3  I have been trying to fetch the data from my F...   \n4  I have a migration like this:   \\n\\n```\\nSchem...   \n5  I need to SELECT the 5 most recent notificatio...   \n6  I have a vector\\n\\n```\\nmyVec <- c('1.2','asd'...   \n7  I stumbled upon the Solver function in my sear...   \n8  I am facing a weird bug.\\n\\nHere is the code f...   \n9  I have some on-premise based frontend java ser...   \n\n                                                Tags  \n0                [\"c#\",\"asp.net-mvc\",\"if-statement\"]  \n1  [\"reactjs\",\"react-hooks\",\"use-effect\",\"js-cook...  \n2        [\"python\",\"docker\",\"environment-variables\"]  \n3  [\"android\",\"firebase\",\"listview\",\"firebase-rea...  \n4                                [\"mysql\",\"laravel\"]  \n5                                 [\"abap\",\"opensql\"]  \n6                              [\"r\",\"regex\",\"grepl\"]  \n7                  [\"excel\",\"vba\",\"random\",\"solver\"]  \n8              [\"python\",\"matplotlib\",\"jupyter-lab\"]  \n9  [\"database\",\"oracle\",\"amazon-web-services\",\"cl...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am very new to C# and I have a question. I d...</td>\n      <td>[\"c#\",\"asp.net-mvc\",\"if-statement\"]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The code runs fine on React 16.8, yet freezes ...</td>\n      <td>[\"reactjs\",\"react-hooks\",\"use-effect\",\"js-cook...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have a python script with:\\n\\n```\\nos.enviro...</td>\n      <td>[\"python\",\"docker\",\"environment-variables\"]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I have been trying to fetch the data from my F...</td>\n      <td>[\"android\",\"firebase\",\"listview\",\"firebase-rea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I have a migration like this:   \\n\\n```\\nSchem...</td>\n      <td>[\"mysql\",\"laravel\"]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I need to SELECT the 5 most recent notificatio...</td>\n      <td>[\"abap\",\"opensql\"]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I have a vector\\n\\n```\\nmyVec &lt;- c('1.2','asd'...</td>\n      <td>[\"r\",\"regex\",\"grepl\"]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>I stumbled upon the Solver function in my sear...</td>\n      <td>[\"excel\",\"vba\",\"random\",\"solver\"]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>I am facing a weird bug.\\n\\nHere is the code f...</td>\n      <td>[\"python\",\"matplotlib\",\"jupyter-lab\"]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>I have some on-premise based frontend java ser...</td>\n      <td>[\"database\",\"oracle\",\"amazon-web-services\",\"cl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nBefore filtering:\nNumber of rows: 150013\nDataset size: 3.43 MB\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │ \u001b[38;5;34m62,617,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m74,496\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m146\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m164,096\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,640\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ batch_normalizat… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">62,617,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">146</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ batch_normalizat… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,883,274\u001b[0m (239.88 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,883,274</span> (239.88 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,882,378\u001b[0m (239.88 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,882,378</span> (239.88 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 35ms/step - accuracy: 0.5160 - loss: 0.5363 - val_accuracy: 0.7912 - val_loss: 0.1434\nEpoch 2/10\n\u001b[1m2032/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 35ms/step - accuracy: 0.7702 - loss: 0.1658 - val_accuracy: 0.8002 - val_loss: 0.1354\nEpoch 3/10\n\u001b[1m1905/2032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.7890 - loss: 0.1549","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\ndef predict_with_confidence(question, threshold=0.35, delta=0.08):\n    sequence = tokenizer.texts_to_sequences([question])\n    padded_sequence = pad_sequences(sequence, maxlen=150)\n    prediction = model.predict(padded_sequence)[0]  # Only one input, get [0]\n    \n    tag_scores = {tag: score for tag, score in zip(top_10_tags, prediction)}\n    sorted_tags = sorted(tag_scores.items(), key=lambda x: x[1], reverse=True)\n\n    best_tag, best_score = sorted_tags[0]\n\n    predicted_tags = [tag for tag, score in tag_scores.items()\n                      if score >= threshold or (best_score - score <= delta)]\n\n    return best_tag, best_score, predicted_tags, tag_scores\n\n\n# Prediction loop\nwhile True:\n    question = input(\"\\nEnter your question (or type 'exit' to quit): \").strip()\n    if question.lower() == 'exit':\n        print(\"Exiting prediction loop.\")\n        break\n\n    best_tag, best_score, predicted_tags, tag_scores = predict_with_confidence(question)\n\n    print(f\"\\nPredicted Top Tag: {best_tag} (Confidence: {best_score:.2f})\")\n    print(f\"Other Relevant Tags: {', '.join(predicted_tags) if predicted_tags else 'None above threshold'}\")\n    print(\"All Tag Scores:\")\n    for tag, score in tag_scores.items():\n        print(f\"  {tag}: {score:.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}